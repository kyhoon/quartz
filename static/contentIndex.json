{"RecSys/A-Comprehensive-Review-of-Recommender-Systems---Transitioning-from-Theory-to-Practice":{"slug":"RecSys/A-Comprehensive-Review-of-Recommender-Systems---Transitioning-from-Theory-to-Practice","filePath":"RecSys/A Comprehensive Review of Recommender Systems - Transitioning from Theory to Practice.md","title":"A Comprehensive Review of Recommender Systems - Transitioning from Theory to Practice","links":["RecSys/Dynamic-Graph-Neural-Networks-for-Sequential-Recommendation","RecSys/Frequency-Enhanced-Hybrid-Attention-Network-for-Sequential-Recommendation","RecSys/Knowledge-Prompt-tuning-for-Sequential-Recommendation","RecSys/Bayesian-Knowledge-driven-Critiquing-with-Indirect-Evidence","RecSys/DiffKG---Knowledge-Graph-Diffusion-Model-for-Recommendation","RecSys/Towards-Hierarchical-Policy-Learning-for-Conversational-Recommendation-with-Hypergraph-based-Reinforcement-Learning","RecSys/RecMind---Large-Language-Model-Powered-Agent-For-Recommendation","RecSys/Adaptive-Multi-Modalities-Fusion-in-Sequential-Recommendation-Systems","RecSys/PromptMM---Multi-Modal-Knowledge-Distillation-for-Recommendation-with-Prompt-Tuning","RecSys/Explainable-Fairness-in-Recommendation","RecSys/Bias-Reduction-News-Recommendation-System","RecSys/Fairness-among-New-Items-in-Cold-Start-Recommender-Systems","RecSys/Monolith---Real-Time-Recommendation-System-With-Collisionless-Embedding-Table","RecSys/Consistent-Collaborative-Filtering-via-Tensor-Decomposition"],"tags":["survey","recsys","todo"],"content":"Abstract\nRecommender Systems (RS) play an integral role in enhancing user experiences by providing personalized item suggestions. This survey reviews the progress in RS inclusively from 2017 to 2024, effectively connecting theoretical advances with practical applications. We explore the development from traditional RS techniques like content-based and collaborative filtering to advanced methods involving deep learning, graph-based models, reinforcement learning, and large language models. We also discuss specialized systems such as context-aware, review-based, and fairness-aware RS. The primary goal of this survey is to bridge theory with practice. It addresses challenges across various sectors, including e-commerce, healthcare, and finance, emphasizing the need for scalable, real-time, and trustworthy solutions. Through this survey, we promote stronger partnerships between academic research and industry practices. The insights offered by this survey aim to guide industry professionals in optimizing RS deployment and to inspire future research directions, especially in addressing emerging technological and societal trends2 . The survey resources are available in the public GitHub repository github.com/VectorInstitute/Recommender-Systems-Survey.\nIntroduction\nMain Contributions\n\nThis survey provides a comprehensive review of RS, tracing their development from theoretical foundations to practical applications between 2017 and 2023. It is the first survey to specifically highlight the translation of theoretical advancements into practical solutions for industry challenges.\nEach type of RS is thoroughly examined, including data input methods, associated challenges, relevant datasets, evaluation metrics, model accuracy, and practical applications, as presented in tables. The survey aims to offer industry professionals a set of guidelines to facilitate the deployment of these systems in real-world settings.\nWe discuss the specific challenges faced by RS in various sectors, such as e-commerce, healthcare, finance, and others. The survey emphasizes the need for scalable, real-time, and privacy-focused solutions, demonstrating how theoretical insights can address these industry-specific demands.\n\n\nTraditional RS methods can be categorized into collaborative filtering, content-based filtering, and hybrid approaches.\nCollaborative filtering (CF) [70] is based on the idea that users with similar preferences will likely have similar tastes in the future. CF recommends items by finding a neighborhood of similar users or items. CF can recommend items without needing much content analysis, however, it normally faces challenges like cold starts, scalability, and sparsity.\n\nContent-based filtering (CBF) [72] recommends items based on a user past preferences and item characteristics, using techniques like Term Frequency- Inverse Document Frequency (TF-IDF), cosine similarity, and neural networks for item representation. However, it may struggle with recommending new or unseen items.\n\nHybrid RS [36] combine the strengths of both approaches, offering more accurate and personalized recommendations by integrating diverse methodologies.\n\nModeling Techniques\nGraph-based Recommender Systems\nGNNs can effectively address various practical challenges by modeling complex relationships in data.\n\n\nDynamic Graph Neural Networks for Sequential Recommendation\n\nSequential and Session-based Recommender Systems\nSequential recommendation is commonly viewed as a next-item or next-basket prediction challenge [37]. Both the sequential and session-based RS leverage user action sequences to anticipate users’ future preferences [95]. Specifically, sequential RS consider the interaction histories of the users to predict future behaviour or users’ preferences. In contrast, session-based RS, detailed in survey [38], focus on short-term user activity for real-time recommendations. These approaches collectively enhance personalization and relevance across diverse platforms.\n\nFrequency Enhanced Hybrid Attention Network for Sequential Recommendation\nKnowledge Prompt-tuning for Sequential Recommendation\n\nKnowledge-based Recommender Systems\nA KG is a directed graph G = (V, E), where V and E represent entities and relations between them, respectively, with E ⊆ V × V . It includes entity type function Φ : V → A and relation type function Ψ : E → R, mapping entities to types A and relations to types R. KGs are depicted as sets of triples ⟨eh, r, et⟩, signifying a relation r from eh to et.\nEmbedding-based approaches focus on learning and applying embeddings to represent KG entities (nodes) and relations (edges), enhancing user and item representations. They typically start with initial embedding generation using models like TransE [309], TransD [198], and node2vec [310], followed by their application in RS through attention mechanisms in KSR [229] or generative models like BEM [176] and KTGAN [311].\nJoint Learning Methods optimize both KG embeddings and recommendation components simultaneously using a unified loss function. Examples include CKE [112], which integrates auto-encoders for item representations, and SHINE [312], which acquires user embeddings from heterogeneous graphs. Multi-Task Methods such as KTUP [221] and MKR [206] address KG-enhanced recommendation and KG completion concurrently, improving both entity/relation representations and recommendations.\nPropagation-based approaches influence embeddings through multi-hop neighbor interactions within the KG. Item KG-based methods like Ripplenet [215] aggregate item-related embeddings to derive user interests, whereas User-Item KG-based methods such as KGAT [197] and Intentgc [195] refine both user and item embeddings by propagating embeddings across a user-item graph, enhancing recommendation accuracy.\nOverall, these systems enable more contextually aware, personalized, and efficient recommendation systems, significantly improving user experience across these sectors.\n\nBayesian Knowledge-driven Critiquing with Indirect Evidence\nDiffKG - Knowledge Graph Diffusion Model for Recommendation\n\nReinforcement Learning-based Recommender Systems\nBy employing techniques such as deep Q-networks and policy gradient methods, RL-based recommender systems continuously refine their decision-making processes, leading to improved long-term user engagement and satisfaction.\n\nTowards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning\n\nLarge Language Model based Recommender Systems\nThe integration of BERT-like models into RS has led to significant advancements. Initial applications like BERT4REC [228] utilized deep bidirectional self-attention for modeling user behavior sequences, while further developments employed BERT for tasks ranging from conversational RS [78] to CTR prediction [339]. Enhancements in BERT-based models have addressed specific RS challenges, such as item alignment in dialogues [340] and user representation through models like U-BERT [341] and UserBERT [342]. Further innovations include BERT-based re-ranking [343] and addressing data sparsity in group recommendations [344].\nPrompt-based and in-context learning (ICL) approaches have leveraged the adaptability of LLMs, employing personalized prompts and natural language processing to enhance recommendation relevance and user interaction without extensive retraining [345, 293].\nLLMs have advanced RS by addressing key challenges such as the cold-start problem, enhancing personalization, and improving accuracy.\n\nRecMind - Large Language Model Powered Agent For Recommendation\n\nMultimodal Recommender Systems\nThe evolution of multi-modal RS began with the introduction of Visual Bayesian Personalized Ranking (VBPR) [349], which enhances personalized ranking by integrating visual features from product images. The results showed improved accuracy and addressing cold-start issues. Attentive Collaborative Filtering (ACF) [350] introduced a novel attention mechanism to better handle item- and component-level feedback in multimedia recommendations.\nCollaborative Cross Networks (CoNet) [351] utilizes deep transfer learning. Multi-Modality enriched Sequential Recommendation (MMSR) [249], a graph-based model, adaptively fuses multi-modal information to dynamically prioritize modalities based on their sequential relationships.\n\nAdaptive Multi-Modalities Fusion in Sequential Recommendation Systems\nPromptMM - Multi-Modal Knowledge Distillation for Recommendation with Prompt-Tuning\n\nSpecialized Recommender Systems\nContext-aware Recommender Systems\nContext-aware recommender systems (CARS) are advanced RS that enhance the personalization of content by incorporating contextual information into the recommendation process [33]. Unlike traditional RS that primarily rely on user-item interactions, CARS consider additional dimensions such as time, location, social settings, and user behavior patterns to deliver more relevant and timely suggestions [352].\nAmong these, factorization machines (FM) [353] are prominent for their ability to capture interactions between variables within large datasets. Field-Aware Factorization Machines (FFMs) [354] are specifically optimized for CTR prediction, showing the versatility and depth of models developed for enhancing CARS’ performance.\nReview-based Recommender Systems\nA review-based RS uses textual reviews and ratings from users to generate personalized recommendations for products or services [358, 45]. The review-based RS have evolved by improving through various models. Initially, models like Hidden Factors as Topics (HFT) [359] aligned topics from reviews with latent dimensions from ratings. Successive approaches, such as Rating-Boosted Latent Topics (RBLT) [360], Topic Initialized Latent Factor Model (TIM) [307], and deep learning models like Convolutional Matrix Factorization (ConvMF) [361] and Deep Cooperative Neural Networks (DeepCoNN) [87], utilized neural networks to better handle sparse data and extract nuanced features from reviews.\nAspect-based Recommender Systems\nAspect-based RS extract and analyze specific product attributes from reviews, providing tailored recommendations to the users based on item aspects [376]. This approach to RS differs with review-based RS, which assess overall user sentiment and preferences from review content.\nAspect-based RS effectively address several practical challenges by focusing on specific product attributes extracted from user reviews. These systems enhance personalization by tailoring recommendations based on individual user preferences and item characteristics.\nExplainable and Trustworthy Recommender Systems\nAdvancements in explainable and trustworthy RS have evolved, starting with phrase-level analysis of user reviews to enhance recommendation explainability by identifying critical item aspects [389]. Subsequent models like Tripartite Graph Ranking (TriRank) have improved top-N recommendations by extracting aspects from reviews and creating a user-item-aspect ternary relation [390]. Concurrently, models such as the Tree-Enhanced Embedding Model (TEM) merge embedding-based and tree-based methods with an attention network to ensure transparency, utilizing rich side information and explicit decision rules [391]. This integration extends to combining CF with structured knowledge bases and unstructured data like textual reviews for personalized and understandable recommendations [392]. Additionally, techniques like RL have been applied to generate flexible, high-quality explanations across recommendation models [251].\nRecent efforts like the Counterfactual Explainable Fairness (CEF) framework focus on identifying and mitigating fairness issues in RS [397].\n\nExplainable Fairness in Recommendation\n\nFairness, Accountability, Transparency, and Ethics (FATE) in Recommender Systems\nFairness in RS, as outlined in [401], refers to the ethical principle and requirement that recommender algorithms allocate resource (information, opportunities, or exposure) in a manner that is equitable and just across different users and items.\nPre-processing Fairness Methods Pre-processing efforts for fairness in RS involve adjusting training data, altering proportions of protected groups (like gender, race, age) through resampling [174] or adding synthetic data [402]. These methods aim to mitigate biases in input data before model training, they struggle to entirely eliminate biases that appear during training or inference.\nIn-processing Fairness Methods In-processing fairness methods in RS primarily utilize ranking approaches and advanced techniques to incorporate fairness directly into model training, yielding more immediate improvements by modifying elements closely tied to the final output. Regularization techniques play a crucial role by embedding fairness constraints or penalties into the objective function to balance accuracy with fairness\nAdversarial learning further enhances fairness by learning representations that maintain independence from sensitive attributes or ensure equitable distribution across groups\nPost-Processing Fairness Methods Post-processing methods involve adjusting the initial output of a recommendation model to satisfy certain fairness criteria before presenting the final recommendations to users.\n\nBias Reduction News Recommendation System\nFairness among New Items in Cold Start Recommender Systems\n\nApplications\nNumerous platforms have leveraged advanced RS technologies to enhance user engagement and content personalization. YouTube employs deep neural networks to refine its recommendation process, focusing on optimal ranking and selection of videos [488]. Google Play utilizes both linear models and neural networks within its Wide &amp; Deep Learning framework to achieve a balance between memorization and generalization [97]. LinkedIn enhances job and content recommendation using real-time processing and scoring mechanisms, integrating CF and deep learning to match job seekers with suitable opportunities [132, 489]. Twitter customizes its content recommendations, like tweets and follower suggestions, based on user behavior and preferences [490].\nByteDance has introduced innovative models for TikTok to quickly adapt recommendations to user interactions, employing unique retrieval models and scalable systems like Monolith, which uses collisionless embedding tables for efficient memory usage [491, 492]. Apple has developed the Sliced Anti-symmetric Decomposition (SAD) model to enhance collaborative filtering, allowing more nuanced user-item interactions, and explores controlled music production using diffusion models [493, 494]. DeepMind’s generative models improve RS by decoding Semantic IDs from user interactions, enhancing item retrieval and system performance [495].\n\nMonolith - Real Time Recommendation System With Collisionless Embedding Table\nConsistent Collaborative Filtering via Tensor Decomposition\n"},"RecSys/Adaptive-Multi-Modalities-Fusion-in-Sequential-Recommendation-Systems":{"slug":"RecSys/Adaptive-Multi-Modalities-Fusion-in-Sequential-Recommendation-Systems","filePath":"RecSys/Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems.md","title":"Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems","links":[],"tags":["recsys","todo"],"content":"Abstract\nIn sequential recommendation, multi-modal information (e.g., text or image) can provide a more comprehensive view of an item’s profile. The optimal stage (early or late) to fuse modality features into item representations is still debated. We propose a graph-based approach (named MMSR) to fuse modality features in an adaptive order, enabling each modality to prioritize either its inherent sequential nature or its interplay with other modalities. MMSR represents each user’s history as a graph, where the modality features of each item in a user’s history sequence are denoted by cross-linked nodes. The edges between homogeneous nodes represent intra-modality sequential relationships, and the ones between heterogeneous nodes represent inter-modality interdependence relationships. During graph propagation, MMSR incorporates dual attention, differentiating homogeneous and heterogeneous neighbors. To adaptively assign nodes with distinct fusion orders, MMSR allows each node’s representation to be asynchronously updated through an update gate. In scenarios where modalities exhibit stronger sequential relationships, the update gate prioritizes updates among homogeneous nodes. Conversely, when the interdependent relationships between modalities are more pronounced, the update gate prioritizes updates among heterogeneous nodes. Consequently, MMSR establishes a fusion order that spans a spectrum from early to late modality fusion. In experiments across six datasets, MMSR consistently outperforms state-of-the-art models, and our graph propagation methods surpass other graph neural networks. Additionally, MMSR naturally manages missing modalities."},"RecSys/Bayesian-Knowledge-driven-Critiquing-with-Indirect-Evidence":{"slug":"RecSys/Bayesian-Knowledge-driven-Critiquing-with-Indirect-Evidence","filePath":"RecSys/Bayesian Knowledge-driven Critiquing with Indirect Evidence.md","title":"Bayesian Knowledge-driven Critiquing with Indirect Evidence","links":["RecSys/SimplE-Embedding-for-Link-Prediction-in-Knowledge-Graphs"],"tags":["recsys"],"content":"Abstract\nConversational recommender systems (CRS) enhance the expressivity and personalization of recommendations through multiple turns of user-system interaction. Critiquing is a well-known paradigm for CRS that allows users to iteratively refine recommendations by providing feedback about attributes of recommended items. While existing critiquing methodologies utilize direct attributes of items to address user requests such as ‘I prefer Western movies’, the opportunity of incorporating richer contextual and side information about items stored in Knowledge Graphs (KG) into the critiquing paradigm has been overlooked. Employing this substantial knowledge together with a well-established reasoning methodology paves the way for critique-based recommenders to allow for complex knowledge-based feedback (e.g., ‘I like movies featuring war side effects on veterans’) which may arise in natural user-system conversations. In this work, we aim to increase the flexibility of critique-based recommendation by integrating KGs and propose a novel Bayesian inference framework that enables reasoning with relational knowledge-based feedback. We study and formulate the framework considering a Gaussian likelihood and evaluate it on two well-known recommendation datasets with KGs. Our evaluations demonstrate the effectiveness of our framework in leveraging indirect KG-based feedback (i.e., preferred relational properties of items rather than preferred items themselves), often improving personalized recommendations over a one-shot recommender by more than 15%. This work enables a new paradigm for using rich knowledge content and reasoning over indirect evidence as a mechanism for critiquing interactions with CRS.\nIntroduction\n\nIn this work, we make the following contributions: (i) We introduce the Gaussian variant of a popular tensor factorization approach for KG-enhanced recommendation. (ii) We propose Bayesian Critiquing with Indirect Evidence (BCIE), a knowledge-driven critiquing framework, and formulate a Bayesian closed-form user belief updating methodology to enable critiquing CRSs to address indirect feedback. (iii) We empirically show that BCIE results in considerable improvement of personalized recommendation over one-shot recommendation by evaluation on two datasets and a KG.\n\nBayesian Critiquing with Indirect Evidence\nIn the conversational critiquing problem setting that we investigate, …\nThe recommender’s duty in the next step is to update its belief in the user’s interests and refine 𝑅𝑢 given 𝑑𝑛, the evidence of the user’s taste observed from the critique at iteration 𝑛. Hence, the recommender needs a critique-modified recommendation function 𝑓𝑚, such that 𝑅ˆ 𝑢 = 𝑓𝑚 (𝑅𝑢, 𝑑𝑛). This process continues either for a fixed number of iterations or until the user accepts the recommendation or leaves the conversation.\nPre-critiquing phase\nWe build our recommender upon SimplE, a well-known tensor factorization-based KG embedding model, because of its efficient computations and full-expressiveness [8]. This model assigns two embedding vectors ℎ𝑒 and 𝑡𝑒 to each entity 𝑒 and two vectors 𝑣𝑟 and 𝑣𝑟 −1 to each relation 𝑟, and defines its scoring function for a triple (𝑒𝑖 , 𝑟, 𝑒𝑗) as Φ(𝑒𝑖 , 𝑟, 𝑒𝑗) = 1 2 (⟨ℎ𝑒,𝑖, 𝑣𝑟, 𝑡𝑒,𝑗⟩+⟨ℎ𝑒,𝑗, 𝑣−1 𝑟 , 𝑡𝑒,𝑖⟩), in which ⟨𝑣,𝑤, 𝑥⟩ = (𝑣 ⊙ 𝑤) · 𝑥 where ⊙ is element-wise and · represents dot product.\n\nSimplE Embedding for Link Prediction in Knowledge Graphs\n\n… Using the learned embeddings of entities and relations, the set of items yielding the highest plausibility scores for (𝑢𝑠𝑒𝑟,𝑙𝑖𝑘𝑒𝑠,𝑖𝑡𝑒𝑚) triples are picked for recommendation.\nCritiquing phase: Bayesian User Belief Updating with Indirect Evidence\nIn each critiquing session, the user provides knowledge-based feedback containing indirect evidence of her preference. … Hence, in the BCIE framework, we need to consider a distribution over representations of items that cover the user’s interest, which is denoted by 𝒛𝒎. To this end, we require to maintain a belief state over the user preferences, hereafter called user belief, which is initially centered at the learned embedding of the user entity and update it conditioned on the user critiques.\n\nThe next challenge is obtaining 𝑱𝒖,𝒛 . Note that by adopting the Gaussian variant of SimplE, the likelihood factor between the user belief distribution 𝒛𝑢 and item distribution 𝒛𝑚 becomes exp{−⟨𝒛𝑢,𝒓, 𝒛𝑚⟩} where 𝒓 is the embedding vector of the likes relation — this is log-bilinear in 𝒛𝑢 and 𝒛𝑚 and would appear to stymie closed-form Gaussian belief propagation. Serendipitously, we can rewrite ⟨𝒛𝒖,𝒓, 𝒛𝒎⟩ as 𝒖 𝑇 𝑫𝒓 𝒛, where 𝑫𝒓 is derived by reshaping 𝑟 as a diagonal matrix. Hence, we have 𝑱𝒖,𝒛 = 𝑫𝑟.\n\nTo summarize, while the use of a tensor-based likelihood introduced an unusual log-bilinear form and the need to marginalize over the latent item distribution induced by the KG critiques, we have shown that we can manipulate all necessary quantities in Gaussian form. In this way, we can perform a closed-form Gaussian user belief update w.r.t. an item distribution inferred by indirect KG properties.\nExperiments and Evaluation\nWe evaluate BCIE1 on two of the most popular recommendation datasets, MovieLens 20M 2 and Amazon-Book 3 , and acquire facts about their items from Freebase KG [2]. We consider ratings greater than 3.5 to indicate that the user likes an item and extract facts about items from Freebase using entity matching data from [20]. Also, since we conduct 5 steps of critiquing, we only keep items with at least 5 KG facts to enable selection of non-repetitive critiques. Table 1 shows dataset statistics.\nAs prior KG-enhanced recommendation studies have not considered the conversational setting and previous critiquing works do not handle knowledge-based indirect evidence, we propose two comparison baselines, namely ’Mapped items’ and ’Direct’. Mapped items is a heuristic method that maps each critique to a maximum of 10 relevant items from the KG and uses them for user belief updating. For example, for the critique “I prefer movies like Nolan’s works”, movies that are directed by, Nolan are mined from the KG and used as examples of the user’s interests.\n\n\n\n(from cedar.buffalo.edu/~srihari/CSE674/Chap7/7.1-MultiGauss.pdf)"},"RecSys/Bias-Reduction-News-Recommendation-System":{"slug":"RecSys/Bias-Reduction-News-Recommendation-System","filePath":"RecSys/Bias Reduction News Recommendation System.md","title":"Bias Reduction News Recommendation System","links":[],"tags":["recsys","todo"],"content":"Abstract\nNews recommender systems (NRS) are crucial for helping users navigate the vast amount of content available online. However, traditional NRS often suffer from biases that lead to a narrow and unfair distribution of exposure across news items. In this paper, we propose a novel approach, the Contextual-Dual Bias Reduction Recommendation System (C-DBRRS), which leverages Long Short-Term Memory (LSTM) networks optimized with a multi-objective function to balance accuracy and diversity. We conducted experiments on two real-world news recommendation datasets and the results indicate that our approach outperforms the baseline methods, and achieves higher accuracy while promoting a fair and balanced distribution of recommendations. This work contributes to the development of a fair and responsible recommendation system."},"RecSys/Consistent-Collaborative-Filtering-via-Tensor-Decomposition":{"slug":"RecSys/Consistent-Collaborative-Filtering-via-Tensor-Decomposition","filePath":"RecSys/Consistent Collaborative Filtering via Tensor Decomposition.md","title":"Consistent Collaborative Filtering via Tensor Decomposition","links":[],"tags":["recsys","todo"],"content":"Abstract\nCollaborative filtering is the de facto standard for analyzing users’ activities and building recommendation systems for items. In this work we develop Sliced Anti-symmetric Decomposition (SAD), a new model for collaborative filtering based on implicit feedback. In contrast to traditional techniques where a latent representation of users (user vectors) and items (item vectors) are estimated, SAD introduces one additional latent vector to each item, using a novel three-way tensor view of user-item interactions. This new vector extends user-item preferences calculated by standard dot products to general inner products, producing interactions between items when evaluating their relative preferences. SAD reduces to state-of-the-art (SOTA) collaborative filtering models when the vector collapses to 1, while in this paper we allow its value to be estimated from data. Allowing the values of the new item vector to be different from 1 has profound implications. It suggests users may have nonlinear mental models when evaluating items, allowing the existence of cycles in pairwise comparisons. We demonstrate the efficiency of SAD in both simulated and real world datasets containing over 1M user-item interactions. By comparing with seven SOTA collaborative filtering models with implicit feedbacks, SAD produces the most consistent personalized preferences, in the meanwhile maintaining top-level of accuracy in personalized recommendations. We release the model and inference algorithms in a Python library this https URL."},"RecSys/DiffKG---Knowledge-Graph-Diffusion-Model-for-Recommendation":{"slug":"RecSys/DiffKG---Knowledge-Graph-Diffusion-Model-for-Recommendation","filePath":"RecSys/DiffKG - Knowledge Graph Diffusion Model for Recommendation.md","title":"DiffKG - Knowledge Graph Diffusion Model for Recommendation","links":[],"tags":["recsys"],"content":"Abstract\nKnowledge Graphs (KGs) have emerged as invaluable resources for enriching recommendation systems by providing a wealth of factual information and capturing semantic relationships among items. Leveraging KGs can significantly enhance recommendation performance. However, not all relations within a KG are equally relevant or beneficial for the target recommendation task. In fact, certain item-entity connections may introduce noise or lack informative value, thus potentially misleading our understanding of user preferences. To bridge this research gap, we propose a novel knowledge graph diffusion model for recommendation, referred to as DiffKG. Our framework integrates a generative diffusion model with a data augmentation paradigm, enabling robust knowledge graph representation learning. This integration facilitates a better alignment between knowledge-aware item semantics and collaborative relation modeling. Moreover, we introduce a collaborative knowledge graph convolution mechanism that incorporates collaborative signals reflecting user-item interaction patterns, guiding the knowledge graph diffusion process. We conduct extensive experiments on three publicly available datasets, consistently demonstrating the superiority of our DiffKG compared to various competitive baselines. We provide the source code repository of our proposed DiffKG model at the following link: : github.com/HKUDS/DiffKG.\nIntroduction\nThe recommendation performance in practical scenarios is significantly hindered by the inherent sparsity of user-item interactions [36, 40]. To mitigate this issue, the integration of a knowledge graph (KG) as a comprehensive information network for items has emerged as a new trend in collaborative filtering, known as knowledge-aware recommendation. Researchers have explored knowledge-aware recommendation through two primary approaches: embedding-based methods and path-based methods. … To combine the strengths of embedding-based and path-based methods, recent research has turned to GNNs as a powerful tool.\nDespite the demonstrated effectiveness of existing knowledge graph (KG)-aware recommendation methods, their performance heavily relies on high-quality input knowledge graphs and can be adversely affected by the presence of noise. … To address these challenges, recent research has proposed the utilization of contrastive learning (CL) techniques to enhance knowledge-aware recommendation.\n… , we propose a unique knowledge graph diffusion paradigm that effectively balances corruption and reconstruction.\n\nWe present a novel recommendation model called DiffKG, which leverages task-relevant item knowledge to enhance the collaborative filtering paradigm. Our approach introduces a new framework that allows for the distillation of high-quality signals from the aggregated representation of noisy knowledge graphs.\nWe propose an integration of the generative diffusion model with the knowledge graph learning framework, designed for knowledge-aware recommendation. This integration allows us to effectively align the semantics of knowledge-aware items with collaborative relation modeling for recommendation purposes.\nOur extensive experimental evaluations substantiate the substantial performance gains achieved by our DiffKG framework when compared to various baseline models across diverse benchmark datasets. Notably, our approach effectively tackles the challenges stemming from data noise and data scarcity, which are known to exert a negative impact on the accuracy of recommendation.\n\nThe Proposed DiffKG Framework\n\nContrastive learning has recently gained remarkable success in the realm of recommendation systems. … Unfortunately, the random augmentation can introduce unwanted noise, and the supplementary knowledge graph view may contain irrelevant information.\nTo tackle these challenges, we propose the use of a generative model to reconstruct a subgraph G ′ 𝑘 of the knowledge graph G𝑘 that specifically contains the relationships relevant to the downstream recommendation task.\nDiffusion with Knowledge Graph\n\nNoise Diffusion Process. In Fig. 2, we can observe that our knowledge graph (KG) diffusion, similar to other diffusion models, consists of two essential processes: the forward process and the reverse process. In order to apply these processes to the KG, we represent the KG using an adjacency matrix.\n… We initialize the initial state 𝝌0 as the original adjacency matrix z𝑖 of the item.\nKnowledge Graph Generation with Diffusion Model. In contrast to other diffusion models that randomly draw Gaussian noises for reverse generation, we have designed a simple inference strategy that aligns with the training of DiffKG for relation prediction in knowledge graphs (KGs).\nIn our inference strategy, we begin by corrupting the original KG relations 𝝌0 in a step-by-step manner during the forward process, resulting in 𝝌T ′ . We then set 𝝌ˆT = 𝝌T ′ and perform reverse denoising, where we ignore the variance and use 𝝌ˆ𝑡−1 = 𝜇𝜃 (𝝌ˆ𝑡 , 𝑡) for deterministic inference. … For each item 𝑖, we select the top 𝑘 zˆ 𝑗 𝑖 (𝑗 ∈ [0, |E | − 1], 𝑗 ∈ J, and |J | = 𝑘) and add 𝑘 relations between item 𝑖 and entities 𝑗 ∈ J.\nCollaborative Knowledge Graph Convolution. To mitigate the potential limitations of the diffusion model in generating a denoised knowledge graph that encompasses pertinent relationships for downstream recommendation tasks, we propose a collaborative knowledge graph convolution (CKGC) mechanism.\nThe loss of collaborative knowledge graph convolution, denoted as L𝑐𝑘𝑔𝑐 , is computed by incorporating user-item interaction information and knowledge graph predictions into the item embedding generation process. Specifically, we begin by aggregating the user-item interaction information A with the predicted relation probabilities from the knowledge graph, represented as 𝝌ˆ0. This aggregation updates the user-item interaction matrix, effectively integrating the knowledge graph information. Next, we combine this updated user-item matrix with the user embeddings E𝑢 to obtain an item embedding E ′ 𝑖 that jointly incorporates both the knowledge graph and user information. Finally, we calculate the mean squared error (MSE) loss between the aggregated item embedding E ′ 𝑖 and the original item embedding E𝑖 , and optimize it alongside the ELBO loss (L𝑒𝑙𝑏𝑜 ).\n\nExperiments\n\n\n"},"RecSys/Dynamic-Graph-Neural-Networks-for-Sequential-Recommendation":{"slug":"RecSys/Dynamic-Graph-Neural-Networks-for-Sequential-Recommendation","filePath":"RecSys/Dynamic Graph Neural Networks for Sequential Recommendation.md","title":"Dynamic Graph Neural Networks for Sequential Recommendation","links":[],"tags":["recsys"],"content":"Abstract\nModeling user preference from his historical sequences is one of the core problems of sequential recommendation. Existing methods in this field are widely distributed from conventional methods to deep learning methods. However, most of them only model users’ interests within their own sequences and ignore the dynamic collaborative signals among different user sequences, making it insufficient to explore users’ preferences. We take inspiration from dynamic graph neural networks to cope with this challenge, modeling the user sequence and dynamic collaborative signals into one framework. We propose a new method named Dynamic Graph Neural Network for Sequential Recommendation (DGSR), which connects different user sequences through a dynamic graph structure, exploring the interactive behavior of users and items with time and order information. Furthermore, we design a Dynamic Graph Recommendation Network to extract user’s preferences from the dynamic graph. Consequently, the next-item prediction task in sequential recommendation is converted into a link prediction between the user node and the item node in a dynamic graph. Extensive experiments on three public benchmarks show that DGSR outperforms several state-of-the-art methods. Further studies demonstrate the rationality and effectiveness of modeling user sequences through a dynamic graph.\nIntroduction\nAlthough these methods have achieved compelling results, we argue that these methods lack explicit modeling of the dynamic collaborative signals among different user sequences\n…(1) These models do not explicitly leverage the collaborative information among different user sequences, in other words, most of them focus on encoding each user’s own sequence, while ignoring the high-order connectivity between different user sequences,\n(2) These models ignore the dynamic influence of the high-order collaboration information at different times.\n\nfirstly, we convert all user sequences into a dynamic graph annotated with time and order information on edges (Section 4.1). Consequently, the user sequences having common items are associated with each other via user → item and item → user connections.\nSecondly, we devise a sub-graph sampling strategy (Section 4.2) to dynamically extract sub-graphs containing user’s sequence and associated sequences.\nThirdly, to encode user’s preference from the sub-graph, we design a Dynamic Graph Recommendation Network (DGRN) (Section 4.3), in which a dynamic attention module is constructed to capture the long-term preference of users and long-term character of items, and a recurrent neural module or attention module is further utilized to learn short-term preference and character of users and items, respectively.\nMethodology\nDynamic Graph Construction\nWhen the user u acts on the item i at time t, an edge e is established between u and i, and e can be represented by the quintuple (u, i, t, o^i_u, o^u_i)\no^i_u is the order of u−i interaction, that is, the position of item i in all items that the u has interacted with. o^u_i refers to the order of u in all user nodes that have interacted with item i.\n\nSub-Graph Sampling\nSpecifically, we first take user node u as the anchor node and select its most recent n first-order neighbors from graph G tk , that is, the historical items that u has interacted with, written as Nu, where n is the maximum length of user sequence (Line 5, 6, and 8 in Algorithm 1).\nNext, for each item i ∈ Nu, we use each of them as an anchor node to sample the set of users who have interacted with them, written as Ni (Line 11, 12, and 14 in Algorithm 1).\nFollowed by analogy, we can obtain the multi-hop neighbors of node u, which could forms u’s m-order sub-graph G m u (tk) of S u (m is hyper-parameter used to control the size of sub-graph).\nDynamic Graph Recommendation Networks\nSimilar to most GNNs, The DGRN component consists of message propagation and node updating components.\nThe message propagation mechanism aims to learn the message propagation information from user to item and item to user in G m u (tk), respectively. The challenge is how to encode the sequential information of neighbors from user and item perspectives, respectively.\nFrom item to user. … we need to extract two types of information from the neighbors of each user node, which are long-term preference and short-term preference respectively. The long-term preference [46] of user reflects his or her inherent characteristics and general preference, which can be induced from the user’s all historical items. The shortterm preference of the user reflects his or her latest interest.\nFrom user to item. … On the one hand, the long-term character can reflect the general characters of the item. For example, the wealthy people usually buy high-end cosmetics. On the other hand, short-term character reflects the newest property of item.\nLong-term Information.\n\nDynamic Graph Attention Mechanism.\n\nShort-term Information.\n\nNode updating\n\nRecommendation and Optimization\n\nExperiments\nTo evaluate the effectiveness of our model, we conduct experiments on three Amazon datasets from real-world platforms [48]: Amazon-CDs, Amazon-Games, and AmazonBeauty. These datasets are widely used in evaluating sequential recommendation methods and are varying in terms of domains, sizes, and sparsity.\n"},"RecSys/Explainable-Fairness-in-Recommendation":{"slug":"RecSys/Explainable-Fairness-in-Recommendation","filePath":"RecSys/Explainable Fairness in Recommendation.md","title":"Explainable Fairness in Recommendation","links":[],"tags":["recsys","todo"],"content":"Abstract\nExisting research on fairness-aware recommendation has mainly focused on the quantification of fairness and the development of fair recommendation models, neither of which studies a more substantial problem—identifying the underlying reason of model disparity in recommendation. This information is critical for recommender system designers to understand the intrinsic recommendation mechanism and provides insights on how to improve model fairness to decision makers. Fortunately, with the rapid development of Explainable AI, we can use model explainability to gain insights into model (un)fairness. In this paper, we study the problem of explainable fairness, which helps to gain insights about why a system is fair or unfair, and guides the design of fair recommender systems with a more informed and unified methodology. Particularly, we focus on a common setting with feature-aware recommendation and exposure unfairness, but the proposed explainable fairness framework is general and can be applied to other recommendation settings and fairness definitions. We propose a Counterfactual Explainable Fairness framework, called CEF, which generates explanations about model fairness that can improve the fairness without significantly hurting the performance. CEF framework formulates an optimization problem to learn the “minimal” change of the input features that changes the recommendation results to a certain level of fairness. Based on the counterfactual recommendation result of each feature, we calculate an explainability score in terms of the fairness-utility trade-off to rank all the feature-based explanations, and select the top ones as fairness explanations."},"RecSys/Fairness-among-New-Items-in-Cold-Start-Recommender-Systems":{"slug":"RecSys/Fairness-among-New-Items-in-Cold-Start-Recommender-Systems","filePath":"RecSys/Fairness among New Items in Cold Start Recommender Systems.md","title":"Fairness among New Items in Cold Start Recommender Systems","links":[],"tags":["recsys","todo"],"content":"Abstract\nThis paper investigates recommendation fairness among new items. While previous efforts have studied fairness in recommender systems and shown success in improving fairness, they mainly focus on scenarios where unfairness arises due to biased prior user-feedback history (like clicks or views). Yet, it is unknown whether new items without any feedback history can be recommended fairly, and if unfairness does exist, how can we provide fair recommendations among these new items in such a cold-start scenario. In detail, we first formalize fairness among new items with the well-known concepts of equal opportunity and Rawlsian Max-Min fairness. We empirically show the prevalence of unfairness in cold start recommender systems. Then we propose a novel learnable post-processing framework as a model blueprint for enhancing fairness, with which we propose two concrete models: a joint-learning generative model, and a score scaling model. Extensive experiments over four public datasets show the effectiveness of the proposed models for enhancing fairness while also preserving recommendation utility."},"RecSys/Frequency-Enhanced-Hybrid-Attention-Network-for-Sequential-Recommendation":{"slug":"RecSys/Frequency-Enhanced-Hybrid-Attention-Network-for-Sequential-Recommendation","filePath":"RecSys/Frequency Enhanced Hybrid Attention Network for Sequential Recommendation.md","title":"Frequency Enhanced Hybrid Attention Network for Sequential Recommendation","links":[],"tags":["recsys"],"content":"Abstract\nThe self-attention mechanism, which equips with a strong capability of modeling long-range dependencies, is one of the extensively used techniques in the sequential recommendation field. However, many recent studies represent that current self-attention based models are low-pass filters and are inadequate to capture high-frequency information. Furthermore, since the items in the user behaviors are intertwined with each other, these models are incomplete to distinguish the inherent periodicity obscured in the time domain. In this work, we shift the perspective to the frequency domain, and propose a novel Frequency Enhanced Hybrid Attention Network for Sequential Recommendation, namely FEARec. In this model, we firstly improve the original time domain self-attention in the frequency domain with a ramp structure to make both low-frequency and high-frequency information could be explicitly learned in our approach. Moreover, we additionally design a similar attention mechanism via auto-correlation in the frequency domain to capture the periodic characteristics and fuse the time and frequency level attention in a union model. Finally, both contrastive learning and frequency regularization are utilized to ensure that multiple views are aligned in both the time domain and frequency domain. Extensive experiments conducted on four widely used benchmark datasets demonstrate that the proposed model performs significantly better than the state-of-the-art approaches.\nIntroduction\nDespite their effectiveness, self-attention used in current Transformer based models is constantly a low-pass filter, which continuously erases high-frequency information according to the theoretical justification in [13, 14].\nTo alleviate these issues, existing methods import local constraints in different ways to complement Transformer-based models. Such as LSAN [17] adopts a novel twin-attention paradigm to capture the global and local preference signals via a self-attention branch and a convolution branch module, respectively.\nMoreover, users’ behaviors on the Internet tend to show certain periodic trends [20–22]. … However, it is difficult to find the periodic behavior patterns hidden in the sequence by directly calculating the overall attention scores of items in the time domain. But in the frequency domain, there emerges some methods [23] constructing models to recognize the periodic characterize with the help of the Fourier transform, which inspires us to tackle this challenge from a new perspective for recommendation.\n\nWe shift the perspective to the frequency domain and design a frequency ramp structure to improve existing time domain self-attention.\nWe propose a novel frequency domain attention based on an autocorrelation mechanism, which discovers similar period-based dependencies by aggregating most relative time delay sequences.\nWe unify the frequency ramp structure with vanilla self-attention and frequency domain attention in one framework and design a frequency domain loss to regularize the model training.\nWe conduct extensive experiments on four public datasets, and the experimental results imply the superiority of the FEARec compared to state-of-the-art baselines.\n\n\nProposed Method\nFrequency Enhanced Hybrid Attention Encoder\nBased on the embedding layer, we develop the item encoder by stacking 𝐿 Frequency Enhanced hybrid Attention (FEA) blocks, which generally consists of three modules, 𝑖.𝑒., frequency ramp structure, hybrid attention layer, and the point-wise Feed Forward Network (FFN).\nFrequency Ramp Structure. In FEARec, instead of preserving all frequency components, we only extract a subset of frequencies for each layer to guarantee that different attention blocks focus on different spectrums. This strategy is used in both time domain attention and frequency domain attention as shown in Figure 2.\n\n\nFrequency Domain Attention Layer. … As discussed in Section 1, by calculating the auto-correlation, we can find the most related time-delay sequences in the frequency domain and thus discover the periodicity hidden in the behaviors.\n\n\nMulti-Task Learning\nContrastive Learning. Contrastive learning aims to minimize the difference between differently augmented views of the same user and maximize the difference between the augmented sequences derived from different users.\nAlthough previous augmentations methods [8] including item cropping, masking, and reordering help to enhance the performance of SR models, the data-level augmentations cannot guarantee a high level of semantic similarity [7]. Instead of using typical data augmentations, we use a dropout-based augmentations methods as shown in the right part of Figure 2, which is proposed in [7, 49]. We let E𝑢 and E ′ 𝑢 pass through the FEA encoder twice for two output views H 𝐿 𝑢 and (H 𝐿 𝑢 ) ′ respectively and model the frequency components to construct harder positive samples by mixing the frequency feature extract from time domain self-attention and frequency autocorrelation attention.\nFrequency Domain Regularization. … Since time-domain and frequency-domain features represent the same semantics, but only in different domains, we assume that the frequency spectrum of similar time-domain features should also be similar. To ensure the alignment of the representation of different augmented views in the frequency domain, we suggest an L1 regularization in the frequency domain as a complement to FEARec, which contributes to enriching the regularization of the spectrum of the augmented views.\nExperiment\n\n"},"RecSys/Knowledge-Prompt-tuning-for-Sequential-Recommendation":{"slug":"RecSys/Knowledge-Prompt-tuning-for-Sequential-Recommendation","filePath":"RecSys/Knowledge Prompt-tuning for Sequential Recommendation.md","title":"Knowledge Prompt-tuning for Sequential Recommendation","links":[],"tags":["recsys"],"content":"Abstract\nPre-trained language models (PLMs) have demonstrated strong performance in sequential recommendation (SR), which are utilized to extract general knowledge. However, existing methods still lack domain knowledge and struggle to capture users’ fine-grained preferences. Meanwhile, many traditional SR methods improve this issue by integrating side information while suffering from information loss. To summarize, we believe that a good recommendation system should utilize both general and domain knowledge simultaneously. Therefore, we introduce an external knowledge base and propose Knowledge Prompt-tuning for Sequential Recommendation (KP4SR). Specifically, we construct a set of relationship templates and transform a structured knowledge graph (KG) into knowledge prompts to solve the problem of the semantic gap. However, knowledge prompts disrupt the original data structure and introduce a significant amount of noise. We further construct a knowledge tree and propose a knowledge tree mask, which restores the data structure in a mask matrix form, thus mitigating the noise problem. We evaluate KP4SR on three real-world datasets, and experimental results show that our approach outperforms state-of-the-art methods on multiple evaluation metrics. Specifically, compared with PLM-based methods, our method improves NDCG@5 and HR@5 by 40.65% and 36.42% on the books dataset, 11.17% and 11.47% on the music dataset, and 22.17% and 19.14% on the movies dataset, respectively. Our code is publicly available at the link: github.com/zhaijianyang/KP4SR.\nIntroduction\n… However, most of these methods only model the IDs of users and items, considering only the user’s sequential preferences, and cannot capture the user’s fine-grained preferences.\n\nA straightforward and simple approach is to describe domain knowledge using natural language text and then use the powerful reasoning ability of PLMs to improve recommendation performance, as shown in Figure 1. However, there are two challenges with this approach: 1) How to convert structured knowledge graphs into text sequences. 2) Converting into text sequences may destroy the original data structure and how to deal with the noise caused by irrelevant entities and relationships.\n\nWe propose KP4SR, which, to the best of our knowledge, is the first work that transforms knowledge graphs into knowledge prompts (KP) to improve SR performance.\nWe construct KP, which addresses the problems of semantic difference between structured knowledge data contained in the KG and the sequential text data used by PLMs and allows for easy utilization of high-order information from the KG.\nWe propose prompt denoising (PD), which mitigates knowledge noise by restoring the KG data structure in the form of a mask matrix.\nWe conduct extensive experiments on three datasets, and the results demonstrate the effectiveness of our method. In addition, ablation experiments show that transforming the SR task into an NLP task still follows the general pattern of NLP, which indicates the great research prospects and research value of PLMs in improving the performance of recommendation systems.\n\n\nProblem Definition\nBy sorting the interactions between users and items by timestamps, we can obtain the interaction sequence 𝑆𝑢 of user 𝑢, which can be represented as 𝑆𝑢 = {𝑣 𝑢 1 , 𝑣𝑢 2 , …, 𝑣𝑢 |𝑢| }, where |𝑢| denotes the length of the sequence, 𝑢 ∈ U and 𝑣 ∈ V. Our goal is to predict the next item 𝑣 𝑢 |𝑢|+1 that the user is likely to interact with.\nOur goal is to incorporate domain knowledge from KG into PLMs to mine users’ complex preferences. For instance, given a basic input sample: “Tom has watched Cast Away, Back to the Future, and is going to watch [mask].”, we need to input the relevant KG information, such as (Cast Away, film.genre, Adventure).\nMethodology\nPrompts Construction\nMasked personalized prompts. … Specifically, MPP can transform the recommendation task into a pre-training task, namely a cloze task, as shown in Figure 3. For a user 𝑢 and his/her interaction sequence {𝐴, 𝐵,𝐶, 𝐷, 𝐸, 𝐹 }, we can fill in the corresponding fields in the template to obtain: User u has previously watched {A, B, C, D, E}, and is going to watch [mask] next. Here, [mask] is the next item to be predicted, i.e., the target item 𝐹 .\n\nMPP can transform the recommendation task into a pre-training task, improving task performance when downstream task data is sparse.\nKnowledge prompts. Using KG as side information in recommendation systems can significantly improve their performance.\nFor a triple (ℎ, 𝑟, 𝑡), where ℎ represents the head entity, 𝑟 represents the relation, and 𝑡 represents the tail entity, we manually design a relation template for each relation 𝑟 ∈ R to express the semantics of the corresponding triple. For example, in Figure 3, we design a template for the relation film.genre: The genre of [X] is [Y]. Then for the triple (Cast Away, film.genre, Adventure), we replace [X] and [Y] with the head and tail entities, respectively, to obtain a basic triple prompt: “The genre of Cast Away is Adventure.”.\nFused Prompt. After obtaining MPP and KP, we directly concatenate them as the input of PLM. Specifically, MPP can be represented as: 𝑋𝑑 = {𝑥1, 𝑥2, …, [𝑚𝑎𝑠𝑘], …, 𝑥𝑚}, where 𝑥𝑖 is the 𝑖-th token of the text sequence, 𝑚 represents the length of the text in tokens, and [𝑚𝑎𝑠𝑘] represents the next item to be predicted.\nPrompt Denoising\nConverting KG to knowledge prompts can disrupt the original data structure and introduce a large amount of irrelevant and noisy knowledge.\nKnowledge tree construction. … The root node of the knowledge tree is the MPP, which contains multiple items that the user has interacted with. Therefore, the knowledge tree has multiple knowledge subtrees.\n… For example, in Figure1, the movie “Cast Away” can be represented by two triplets: (Cast Away, genre, Adventure) and (Cast Away, starred, Tom Hanks). We use 𝐴 to represent “Cast Away”, 𝐴1 to represent “Adventure”, and 𝐴2 to represent “Tom Hanks.” By introducing the relationship templates “The genre of [X] is [Y].” and “[X] starring [Y].”, we obtain two triplet prompts for 𝐴: “𝐴𝐴1: The genre of Cast Away is Adventure.” and “𝐴𝐴2: Cast Away starring Tom Hanks.”. 𝐴𝐴1 and 𝐴𝐴2 are 1-hop triplet prompts for 𝐴.\nKnowledge tree mask. … Triple prompts without logical and semantic relationships will generate much noise, and we should limit their mutual influence.\n\n\nTraining and Recommendation\nWe employ the T5 model architecture [28],which is an encoder-decoder-based pre-trained language model using mask prediction as the pre-training task. We construct personalized prompts with masks, transforming the recommendation task into a mask prediction task similar to the pre-training task of PLMs.\nExperiments\nWe conduct experiments on three public datasets: Amazon books [12], LFM-1b [11], and Movielens-10M [30]. These datasets record the interaction information between users and books, music, and movies.\nThe KG we used is from KB4Rec [45], which links the above three widely used datasets with the widespread knowledge base Freebase[1] to provide side information for recommendation systems.\n"},"RecSys/Monolith---Real-Time-Recommendation-System-With-Collisionless-Embedding-Table":{"slug":"RecSys/Monolith---Real-Time-Recommendation-System-With-Collisionless-Embedding-Table","filePath":"RecSys/Monolith - Real Time Recommendation System With Collisionless Embedding Table.md","title":"Monolith - Real Time Recommendation System With Collisionless Embedding Table","links":[],"tags":["recsys","todo"],"content":"Abstract\nBuilding a scalable and real-time recommendation system is vital for many businesses driven by time-sensitive customer feedback, such as short-videos ranking or online ads. Despite the ubiquitous adoption of production-scale deep learning frameworks like TensorFlow or PyTorch, these general-purpose frameworks fall short of business demands in recommendation scenarios for various reasons: on one hand, tweaking systems based on static parameters and dense computations for recommendation with dynamic and sparse features is detrimental to model quality; on the other hand, such frameworks are designed with batch-training stage and serving stage completely separated, preventing the model from interacting with customer feedback in real-time. These issues led us to reexamine traditional approaches and explore radically different design choices. In this paper, we present Monolith, a system tailored for online training. Our design has been driven by observations of our application workloads and production environment that reflects a marked departure from other recommendations systems. Our contributions are manifold: first, we crafted a collisionless embedding table with optimizations such as expirable embeddings and frequency filtering to reduce its memory footprint; second, we provide an production-ready online training architecture with high fault-tolerance; finally, we proved that system reliability could be traded-off for real-time learning. Monolith has successfully landed in the BytePlus Recommend product."},"RecSys/PromptMM---Multi-Modal-Knowledge-Distillation-for-Recommendation-with-Prompt-Tuning":{"slug":"RecSys/PromptMM---Multi-Modal-Knowledge-Distillation-for-Recommendation-with-Prompt-Tuning","filePath":"RecSys/PromptMM - Multi-Modal Knowledge Distillation for Recommendation with Prompt-Tuning.md","title":"PromptMM - Multi-Modal Knowledge Distillation for Recommendation with Prompt-Tuning","links":[],"tags":["recsys","todo"],"content":"Abstract\nMultimedia online platforms (e.g., Amazon, TikTok) have greatly benefited from the incorporation of multimedia (e.g., visual, textual, and acoustic) content into their personal recommender systems. These modalities provide intuitive semantics that facilitate modality-aware user preference modeling. However, two key challenges in multi-modal recommenders remain unresolved: i) The introduction of multi-modal encoders with a large number of additional parameters causes overfitting, given high-dimensional multi-modal features provided by extractors (e.g., ViT, BERT). ii) Side information inevitably introduces inaccuracies and redundancies, which skew the modality-interaction dependency from reflecting true user preference. To tackle these problems, we propose to simplify and empower recommenders through Multi-modal Knowledge Distillation (PromptMM) with the prompt-tuning that enables adaptive quality distillation. Specifically, PromptMM conducts model compression through distilling u-i edge relationship and multi-modal node content from cumbersome teachers to relieve students from the additional feature reduction parameters. To bridge the semantic gap between multi-modal context and collaborative signals for empowering the overfitting teacher, soft prompt-tuning is introduced to perform student task-adaptive. Additionally, to adjust the impact of inaccuracies in multimedia data, a disentangled multi-modal list-wise distillation is developed with modality-aware re-weighting mechanism. Experiments on real-world data demonstrate PromptMM’s superiority over existing techniques. Ablation tests confirm the effectiveness of key components. Additional tests show the efficiency and effectiveness."},"RecSys/RecMind---Large-Language-Model-Powered-Agent-For-Recommendation":{"slug":"RecSys/RecMind---Large-Language-Model-Powered-Agent-For-Recommendation","filePath":"RecSys/RecMind - Large Language Model Powered Agent For Recommendation.md","title":"RecMind - Large Language Model Powered Agent For Recommendation","links":[],"tags":["recsys","todo"],"content":"Abstract\nWhile the recommendation system (RS) has advanced significantly through deep learning, current RS approaches usually train and fine-tune models on task-specific datasets, limiting their generalizability to new recommendation tasks and their ability to leverage external knowledge due to model scale and data size constraints. Thus, we designed an LLM-powered autonomous recommender agent, RecMind, which is capable of leveraging external knowledge, utilizing tools with careful planning to provide zero-shot personalized recommendations. We propose a Self-Inspiring algorithm to improve the planning ability. At each intermediate step, the LLM self-inspires to consider all previously explored states to plan for the next step. This mechanism greatly improves the model’s ability to comprehend and utilize historical information in planning for recommendation. We evaluate RecMind’s performance in various recommendation scenarios. Our experiment shows that RecMind outperforms existing zero/few-shot LLM-based recommendation baseline methods in various tasks and achieves comparable performance to a fully trained recommendation model P5."},"RecSys/SimplE-Embedding-for-Link-Prediction-in-Knowledge-Graphs":{"slug":"RecSys/SimplE-Embedding-for-Link-Prediction-in-Knowledge-Graphs","filePath":"RecSys/SimplE Embedding for Link Prediction in Knowledge Graphs.md","title":"SimplE Embedding for Link Prediction in Knowledge Graphs","links":[],"tags":["recsys","todo"],"content":"Abstract\nKnowledge graphs contain knowledge about the world and provide a structured representation of this knowledge. Current knowledge graphs contain only a small subset of what is true in the world. Link prediction approaches aim at predicting new links for a knowledge graph given the existing links among the entities. Tensor factorization approaches have proved promising for such link prediction problems. Proposed in 1927, Canonical Polyadic (CP) decomposition is among the first tensor factorization approaches. CP generally performs poorly for link prediction as it learns two independent embedding vectors for each entity, whereas they are really tied. We present a simple enhancement of CP (which we call SimplE) to allow the two embeddings of each entity to be learned dependently. The complexity of SimplE grows linearly with the size of embeddings. The embeddings learned through SimplE are interpretable, and certain types of background knowledge can be incorporated into these embeddings through weight tying. We prove SimplE is fully expressive and derive a bound on the size of its embeddings for full expressivity. We show empirically that, despite its simplicity, SimplE outperforms several state-of-the-art tensor factorization techniques. SimplE’s code is available on GitHub at github.com/Mehran-k/SimplE."},"RecSys/Towards-Hierarchical-Policy-Learning-for-Conversational-Recommendation-with-Hypergraph-based-Reinforcement-Learning":{"slug":"RecSys/Towards-Hierarchical-Policy-Learning-for-Conversational-Recommendation-with-Hypergraph-based-Reinforcement-Learning","filePath":"RecSys/Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning.md","title":"Towards Hierarchical Policy Learning for Conversational Recommendation with Hypergraph-based Reinforcement Learning","links":[],"tags":["recsys"],"content":"Abstract\nConversational recommendation systems (CRS) aim to timely and proactively acquire user dynamic preferred attributes through conversations for item recommendation. In each turn of CRS, there naturally have two decision-making processes with different roles that influence each other: 1) director, which is to select the follow-up option (i.e., ask or recommend) that is more effective for reducing the action space and acquiring user preferences; and 2) actor, which is to accordingly choose primitive actions (i.e., asked attribute or recommended item) that satisfy user preferences and give feedback to estimate the effectiveness of the director’s option. However, existing methods heavily rely on a unified decision-making module or heuristic rules, while neglecting to distinguish the roles of different decision procedures, as well as the mutual influences between them. To address this, we propose a novel Director-Actor Hierarchical Conversational Recommender (DAHCR), where the director selects the most effective option, followed by the actor accordingly choosing primitive actions that satisfy user preferences. Specifically, we develop a dynamic hypergraph to model user preferences and introduce an intrinsic motivation to train from weak supervision over the director. Finally, to alleviate the bad effect of model bias on the mutual influence between the director and actor, we model the director’s option by sampling from a categorical distribution. Extensive experiments demonstrate that DAHCR outperforms state-of-the-art methods.\nIntroduction\n\nConversational recommendation systems (CRS) aim to dynamically learn user preferences by iteratively interacting with the user.\nFor each turn in CRS, the system naturally includes two essential decision-make procedures, when to recommend (i.e., ask or recommend), and what to talk about (i.e., the specific attribute/items). … Early works [Lei et al., 2020a; Sun and Zhang, 2018] develop policy learning for a subset of decision procedures and outsource the other procedures to heuristic rules (SCPR as illustrated in Figure 1 (a)). These works isolate strategies for different decisions and make policy learning hard to converge due to their lack of mutual influence during training. To solve this problem, Deng et al. [2021] and Zhang et al. [2022] develop unified policy learning frameworks (Unicorn as illustrated in Figure 1 (b))\n… Despite effectiveness, the unified strategy brings out issues to be solved: (i) The unified strategy complicates the action selection of the CRS strategy by enlarging the action space and introducing data bias into the action space due to the imbalance in the number of items and attributes. (ii) The unified strategy ignores the different roles of the two decision procedures, leading to the sub-optimal CRS strategy.\nThere remain three challenges in modeling these two roles and their mutual influence. The first challenge is weak supervision. … The second challenge is user preference modeling. In the scenario of CRS, the user likes/dislikes items since they satisfy some attributes, which is a three-order relation (i.e., user-attribute-item). To specify the attributes that motivate the user to like/dislike the item, we should model user preferences with such high-order relations. The third challenge is the bad effect of model bias [Battaglia et al., 2018; Tarvainen and Valpola, 2017] on the mutual influence between director and actor.\n\nWe emphasize the different roles in two decision procedures for CRS, and the mutual influence between them.\nWe propose a novel Director-Actor Hierarchical conversational recommender with intrinsic motivation to train from weak supervision and a dynamic hypergraph to learn user preferences from high-order relations. To alleviate the bad effect of model bias on the mutual influence between director and actor, DAHCR models the director’s options by sampling from a categorical distribution with Gumbel-softmax.\nWe conduct extensive experiments on two benchmark datasets, and DAHCR effectively improves the performance of conversational recommendation.\n\nThe Proposed Model\nThen at each turn t, MCR can either ask the user an attribute pt ∈ Pcand or recommend a certain number of items (e.g., the top ten items) Vt ⊆ Vcand to the user. According to the target item v ∗ and its associated attributes Pv ∗ , the user will choose to accept or reject the proposal of MCR. Based on the user’s feedback, MCR will update the candidate attribute set Pcand and the candidate item set Vcand.\nDAHCR Framework\n\n\n\n\nDAHCR Policy Learning\n\n\nExperiments\n\n"},"Robotics/DexterityGen---Foundation-Controller-for-Unprecedented-Dexterity":{"slug":"Robotics/DexterityGen---Foundation-Controller-for-Unprecedented-Dexterity","filePath":"Robotics/DexterityGen - Foundation Controller for Unprecedented Dexterity.md","title":"DexterityGen - Foundation Controller for Unprecedented Dexterity","links":[],"tags":["robotics","todo"],"content":"Abstract\nTeaching robots dexterous manipulation skills, such as tool use, presents a significant challenge. Current approaches can be broadly categorized into two strategies: human teleoperation (for imitation learning) and sim-to-real reinforcement learning. The first approach is difficult as it is hard for humans to produce safe and dexterous motions on a different embodiment without touch feedback. The second RL-based approach struggles with the domain gap and involves highly task-specific reward engineering on complex tasks. Our key insight is that RL is effective at learning low-level motion primitives, while humans excel at providing coarse motion commands for complex, long-horizon tasks. Therefore, the optimal solution might be a combination of both approaches. In this paper, we introduce DexterityGen (DexGen), which uses RL to pretrain large-scale dexterous motion primitives, such as in-hand rotation or translation. We then leverage this learned dataset to train a dexterous foundational controller. In the real world, we use human teleoperation as a prompt to the controller to produce highly dexterous behavior. We evaluate the effectiveness of DexGen in both simulation and real world, demonstrating that it is a general-purpose controller that can realize input dexterous manipulation commands and significantly improves stability by 10-100x measured as duration of holding objects across diverse tasks. Notably, with DexGen we demonstrate unprecedented dexterous skills including diverse object reorientation and dexterous tool use such as pen, syringe, and screwdriver for the first time."},"Robotics/HAMSTER---Hierarchical-Action-Models-For-Open-World-Robot-Manipulation":{"slug":"Robotics/HAMSTER---Hierarchical-Action-Models-For-Open-World-Robot-Manipulation","filePath":"Robotics/HAMSTER - Hierarchical Action Models For Open-World Robot Manipulation.md","title":"HAMSTER - Hierarchical Action Models For Open-World Robot Manipulation","links":[],"tags":["robotics","todo"],"content":"Abstract\nLarge foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is the lack of robotic data, which are typically obtained through expensive on-robot operation. A promising remedy is to leverage cheaper, off-domain data such as action-free videos, hand-drawn sketches or simulation data. In this work, we posit that hierarchical vision-language-action (VLA) models can be more effective in utilizing off-domain data than standard monolithic VLA models that directly finetune vision-language models (VLMs) to predict actions. In particular, we study a class of hierarchical VLA models, where the high-level VLM is finetuned to produce a coarse 2D path indicating the desired robot end-effector trajectory given an RGB image and a task description. The intermediate 2D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Doing so alleviates the high-level VLM from fine-grained action prediction, while reducing the low-level policy’s burden on complex task-level reasoning. We show that, with the hierarchical design, the high-level VLM can transfer across significant domain gaps between the off-domain finetuning data and real-robot testing scenarios, including differences on embodiments, dynamics, visual appearances and task semantics, etc. In the real-robot experiments, we observe an average of 20% improvement in success rate across seven different axes of generalization over OpenVLA, representing a 50% relative gain. Visual results, code, and dataset are provided at: this https URL"},"Robotics/HOVER---Versatile-Neural-Whole-Body-Controller-for-Humanoid-Robots":{"slug":"Robotics/HOVER---Versatile-Neural-Whole-Body-Controller-for-Humanoid-Robots","filePath":"Robotics/HOVER - Versatile Neural Whole-Body Controller for Humanoid Robots.md","title":"HOVER - Versatile Neural Whole-Body Controller for Humanoid Robots","links":[],"tags":["robotics","todo"],"content":"Abstract\nHumanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control. For example, navigation relies on root velocity tracking, while tabletop manipulation prioritizes upper-body joint angle tracking. Existing approaches typically train individual policies tailored to a specific command space, limiting their transferability across modes. We present the key insight that full-body kinematic motion imitation can serve as a common abstraction for all these tasks and provide general-purpose motor skills for learning multiple modes of whole-body control. Building on this, we propose HOVER (Humanoid Versatile Controller), a multi-mode policy distillation framework that consolidates diverse control modes into a unified policy. HOVER enables seamless transitions between control modes while preserving the distinct advantages of each, offering a robust and scalable solution for humanoid control across a wide range of modes. By eliminating the need for policy retraining for each control mode, our approach improves efficiency and flexibility for future humanoid applications."},"Robotics/Learning-Human-to-Humanoid-Real-Time-Whole-Body-Teleoperation":{"slug":"Robotics/Learning-Human-to-Humanoid-Real-Time-Whole-Body-Teleoperation","filePath":"Robotics/Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation.md","title":"Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation","links":[],"tags":["robotics","todo"],"content":"Abstract\nWe present Human to Humanoid (H2O), a reinforcement learning (RL) based framework that enables real-time whole-body teleoperation of a full-sized humanoid robot with only an RGB camera. To create a large-scale retargeted motion dataset of human movements for humanoid robots, we propose a scalable “sim-to-data” process to filter and pick feasible motions using a privileged motion imitator. Afterwards, we train a robust real-time humanoid motion imitator in simulation using these refined motions and transfer it to the real humanoid robot in a zero-shot manner. We successfully achieve teleoperation of dynamic whole-body motions in real-world scenarios, including walking, back jumping, kicking, turning, waving, pushing, boxing, etc. To the best of our knowledge, this is the first demonstration to achieve learning-based real-time whole-body humanoid teleoperation."},"Robotics/Magma---A-Foundation-Model-for-Multimodal-AI-Agents":{"slug":"Robotics/Magma---A-Foundation-Model-for-Multimodal-AI-Agents","filePath":"Robotics/Magma - A Foundation Model for Multimodal AI Agents.md","title":"Magma - A Foundation Model for Multimodal AI Agents","links":[],"tags":["robotics","todo"],"content":"Abstract\nWe present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds. Magma is a significant extension of vision-language (VL) models in that it not only retains the VL understanding ability (verbal intelligence) of the latter, but is also equipped with the ability to plan and act in the visual-spatial world (spatial-temporal intelligence) and complete agentic tasks ranging from UI navigation to robot manipulation. To endow the agentic capabilities, Magma is pretrained on large amounts of heterogeneous datasets spanning from images, videos to robotics data, where the actionable visual objects (e.g., clickable buttons in GUI) in images are labeled by Set-of-Mark (SoM) for action grounding, and the object movements (e.g., the trace of human hands or robotic arms) in videos are labeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show that SoM and ToM reach great synergy and facilitate the acquisition of spatial-temporal intelligence for our Magma model, which is fundamental to a wide range of tasks as shown in Fig.1. In particular, Magma creates new state-of-the-art results on UI navigation and robotic manipulation tasks, outperforming previous models that are specifically tailored to these tasks. On image and video-related multimodal tasks, Magma also compares favorably to popular large multimodal models that are trained on much larger datasets. We make our model and code public for reproducibility at this https URL."},"Robotics/π_{0.5}---a-Vision-Language-Action-Model-with-Open-World-Generalization":{"slug":"Robotics/π_{0.5}---a-Vision-Language-Action-Model-with-Open-World-Generalization","filePath":"Robotics/π_{0.5} - a Vision-Language-Action Model with Open-World Generalization.md","title":"π_{0.5} - a Vision-Language-Action Model with Open-World Generalization","links":[],"tags":["robotics","todo"],"content":"Abstract\nIn order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab. While vision-language-action (VLA) models have demonstrated impressive results for end-to-end robot control, it remains an open question how far such models can generalize in the wild. We describe \\pi_{0.5}, a new model based on \\pi_{0} that uses co-training on heterogeneous tasks to enable broad generalization. \\pi_{0.5}\\ uses data from multiple robots, high-level semantic prediction, web data, and other sources to enable broadly generalizable real-world robotic manipulation. Our system uses a combination of co-training and hybrid multi-modal examples that combine image observations, language commands, object detections, semantic subtask prediction, and low-level actions. Our experiments show that this kind of knowledge transfer is essential for effective generalization, and we demonstrate for the first time that an end-to-end learning-enabled robotic system can perform long-horizon and dexterous manipulation skills, such as cleaning a kitchen or bedroom, in entirely new homes."},"index":{"slug":"index","filePath":"index.md","title":"👋 Welcome","links":["RecSys/","Robotics/"],"tags":[],"content":"This is where I put whatever I’m currently reading or interested in — mostly papers, notes, and personal reflections.\n📚 Topics\n\nRecommender Systems\n→ See: RecSys\n\n\nRobotics\n→ See: Robotics\n\nFeel free to explore via the graph view (top right), tags, or backlinks. Everything is a work in progress — and that’s the point."}}