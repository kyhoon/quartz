<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">
    <channel>
      <title>Young&#039;s Notes</title>
      <link>https://kyhoon.github.io/quartz</link>
      <description>Last 10 notes on Young&#039;s Notes</description>
      <generator>Quartz -- quartz.jzhao.xyz</generator>
      <item>
    <title>DexterityGen - Foundation Controller for Unprecedented Dexterity</title>
    <link>https://kyhoon.github.io/quartz/Robotics/DexterityGen---Foundation-Controller-for-Unprecedented-Dexterity</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/DexterityGen---Foundation-Controller-for-Unprecedented-Dexterity</guid>
    <description>Abstract Teaching robots dexterous manipulation skills, such as tool use, presents a significant challenge.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>HAMSTER - Hierarchical Action Models For Open-World Robot Manipulation</title>
    <link>https://kyhoon.github.io/quartz/Robotics/HAMSTER---Hierarchical-Action-Models-For-Open-World-Robot-Manipulation</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/HAMSTER---Hierarchical-Action-Models-For-Open-World-Robot-Manipulation</guid>
    <description>Abstract Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>HOVER - Versatile Neural Whole-Body Controller for Humanoid Robots</title>
    <link>https://kyhoon.github.io/quartz/Robotics/HOVER---Versatile-Neural-Whole-Body-Controller-for-Humanoid-Robots</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/HOVER---Versatile-Neural-Whole-Body-Controller-for-Humanoid-Robots</guid>
    <description>Abstract Humanoid whole-body control requires adapting to diverse tasks such as navigation, loco-manipulation, and tabletop manipulation, each demanding a different mode of control.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>Learning Human-to-Humanoid Real-Time Whole-Body Teleoperation</title>
    <link>https://kyhoon.github.io/quartz/Robotics/Learning-Human-to-Humanoid-Real-Time-Whole-Body-Teleoperation</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/Learning-Human-to-Humanoid-Real-Time-Whole-Body-Teleoperation</guid>
    <description>Abstract We present Human to Humanoid (H2O), a reinforcement learning (RL) based framework that enables real-time whole-body teleoperation of a full-sized humanoid robot with only an RGB camera.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>Magma - A Foundation Model for Multimodal AI Agents</title>
    <link>https://kyhoon.github.io/quartz/Robotics/Magma---A-Foundation-Model-for-Multimodal-AI-Agents</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/Magma---A-Foundation-Model-for-Multimodal-AI-Agents</guid>
    <description>Abstract We present Magma, a foundation model that serves multimodal AI agentic tasks in both the digital and physical worlds.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>Ï€_{0.5} - a Vision-Language-Action Model with Open-World Generalization</title>
    <link>https://kyhoon.github.io/quartz/Robotics/%CF%80_%7B0.5%7D---a-Vision-Language-Action-Model-with-Open-World-Generalization</link>
    <guid>https://kyhoon.github.io/quartz/Robotics/%CF%80_%7B0.5%7D---a-Vision-Language-Action-Model-with-Open-World-Generalization</guid>
    <description>Abstract In order for robots to be useful, they must perform practically relevant tasks in the real world, outside of the lab.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>ðŸ‘‹ Welcome</title>
    <link>https://kyhoon.github.io/quartz/</link>
    <guid>https://kyhoon.github.io/quartz/</guid>
    <description>This is where I put whatever Iâ€™m currently reading or interested in â€” mostly papers, notes, and personal reflections.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>A Comprehensive Review of Recommender Systems - Transitioning from Theory to Practice</title>
    <link>https://kyhoon.github.io/quartz/recsys/A-Comprehensive-Review-of-Recommender-Systems---Transitioning-from-Theory-to-Practice</link>
    <guid>https://kyhoon.github.io/quartz/recsys/A-Comprehensive-Review-of-Recommender-Systems---Transitioning-from-Theory-to-Practice</guid>
    <description>Abstract Recommender Systems (RS) play an integral role in enhancing user experiences by providing personalized item suggestions.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>Adaptive Multi-Modalities Fusion in Sequential Recommendation Systems</title>
    <link>https://kyhoon.github.io/quartz/recsys/Adaptive-Multi-Modalities-Fusion-in-Sequential-Recommendation-Systems</link>
    <guid>https://kyhoon.github.io/quartz/recsys/Adaptive-Multi-Modalities-Fusion-in-Sequential-Recommendation-Systems</guid>
    <description>Abstract In sequential recommendation, multi-modal information (e.g., text or image) can provide a more comprehensive view of an itemâ€™s profile.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item><item>
    <title>Bayesian Knowledge-driven Critiquing with Indirect Evidence</title>
    <link>https://kyhoon.github.io/quartz/recsys/Bayesian-Knowledge-driven-Critiquing-with-Indirect-Evidence</link>
    <guid>https://kyhoon.github.io/quartz/recsys/Bayesian-Knowledge-driven-Critiquing-with-Indirect-Evidence</guid>
    <description>Abstract Conversational recommender systems (CRS) enhance the expressivity and personalization of recommendations through multiple turns of user-system interaction.</description>
    <pubDate>Mon, 19 May 2025 05:58:26 GMT</pubDate>
  </item>
    </channel>
  </rss>